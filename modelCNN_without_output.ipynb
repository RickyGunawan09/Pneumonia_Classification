{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of FinalProject_RickyGunawan_revisi3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhOXnsqqM8ST"
      },
      "source": [
        "zip_path = '/content/drive/My\\ Drive/BCML/FinalProject/chest_xray_backup.zip'\n",
        "\n",
        "!cp {zip_path} /content/\n",
        "\n",
        "!cd /content/\n",
        "\n",
        "!unzip -q /content/chest_xray_backup.zip -d /content\n",
        "\n",
        "!rm /content/chest_xray_backup.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBytkJzwr3lv"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import datetime\n",
        "import pandas as pd\n",
        "from numpy import expand_dims\n",
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization,MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD , RMSprop,Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator,img_to_array, load_img\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w5-YJ9yCBUZ"
      },
      "source": [
        "# **Definisi Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnwOI-sGBaUP"
      },
      "source": [
        "labels = [ 'NORMAL','PNEUMONIA']\n",
        "img_size = 200\n",
        "dataset_dir_train = '/content/chest_xray_backup/train'\n",
        "dataset_dir_val = '/content/chest_xray_backup/val'\n",
        "dataset_dir_test = '/content/chest_xray_backup/test'\n",
        "\n",
        "def get_training_data(data_dir):\n",
        "    data = [] \n",
        "    for label in labels: \n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) \n",
        "                data.append([resized_arr, class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return np.array(data)\n",
        "\n",
        "def process_data(img):\n",
        "    img = np.array(img)/255.0\n",
        "    img = np.reshape(img, (200,200,1))\n",
        "    return img\n",
        "\n",
        "def compose_dataset(df):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for img, label in df.values:\n",
        "        data.append(process_data(img))\n",
        "        labels.append(label)\n",
        "        \n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "def imagedatagenerator(param):\n",
        "    test_Image_DG=cv2.imread('/content/chest_xray_backup/train/NORMAL/IM-0115-0001.jpeg', cv2.IMREAD_GRAYSCALE)   # Reading an Image\n",
        "    test_Image_DG=cv2.resize(test_Image_DG,(200,200))              \n",
        "    test_Image_DG = np.array(test_Image_DG)/255.0\n",
        "    test_Image_DG = np.reshape(test_Image_DG, (200,200,1))\n",
        "    input_image_DG= np.expand_dims(test_Image_DG, axis=0)\n",
        "\n",
        "    if param == \"rotation_range\":\n",
        "        datagen_rotation_range = ImageDataGenerator(rotation_range =30)\n",
        "        it = datagen_rotation_range.flow(input_image_DG, batch_size=1)\n",
        "    elif param == \"zoom_range\":\n",
        "        datagen_zoom_range = ImageDataGenerator(zoom_range =0.2)\n",
        "        it = datagen_zoom_range.flow(input_image_DG, batch_size=1)\n",
        "    elif param == \"width_shift_range\":\n",
        "        datagen_width_shift = ImageDataGenerator(width_shift_range =0.1)\n",
        "        it = datagen_width_shift.flow(input_image_DG, batch_size=1)\n",
        "    elif param == \"height_shift_range\":\n",
        "        datagen_height_shift_range = ImageDataGenerator(height_shift_range =0.1)\n",
        "        it = datagen_height_shift_range.flow(input_image_DG, batch_size=1)\n",
        "    elif param == \"horizontal_flip\":\n",
        "        datagen_horizontal_flip = ImageDataGenerator(horizontal_flip =True)\n",
        "        it = datagen_horizontal_flip.flow(input_image_DG, batch_size=1)\n",
        "    elif param == \"All\":\n",
        "        datagen_all = ImageDataGenerator(rotation_range =30,zoom_range =0.2,width_shift_range =0.1,height_shift_range =0.1,horizontal_flip =True)\n",
        "        it = datagen_all.flow(input_image_DG, batch_size=1)\n",
        "\n",
        "    fig=plt.figure(figsize=(30,30))\n",
        "    for i in range(8):\n",
        "        ax=fig.add_subplot(1,8,i+1)\n",
        "        batch = it.next()\n",
        "        image = batch[0]\n",
        "        image = image[:,:,0]\n",
        "        ax.imshow(image,cmap='gray')\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DelslSQ0Cdwg"
      },
      "source": [
        "# **Mengambil Data Image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIrhzGAxHBj4"
      },
      "source": [
        "train = get_training_data(dataset_dir_train)\n",
        "test = get_training_data(dataset_dir_test)\n",
        "val = get_training_data(dataset_dir_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2IcnUCEFQfR"
      },
      "source": [
        "train[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSAYlwXjOqRJ"
      },
      "source": [
        "labels[train[0][1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL6Qsx0QOzln"
      },
      "source": [
        "labels[train[-1][1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r_FEHQvHnx6"
      },
      "source": [
        "train_df = pd.DataFrame(train, columns=['image', 'label'])\n",
        "test_df = pd.DataFrame(test, columns=['image', 'label'])\n",
        "val_df = pd.DataFrame(val, columns=['image', 'label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vJ1XFCzIkZn"
      },
      "source": [
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnRX_rO5CqFz"
      },
      "source": [
        "# **Visualisasi Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxf8A3J3IHi-"
      },
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "sns.countplot(train_df['label'])\n",
        "plt.title('Train data')\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "sns.countplot(test_df['label'])\n",
        "plt.title('Test data')\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "sns.countplot(val_df['label'])\n",
        "plt.title('Validation data')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtmCWd6xJiEx"
      },
      "source": [
        "plt.figure(figsize = (5,5))\n",
        "plt.imshow(train[0][0], cmap='gray')\n",
        "plt.title(labels[train[0][1]])\n",
        "\n",
        "plt.figure(figsize = (5,5))\n",
        "plt.imshow(train[-1][0], cmap='gray')\n",
        "plt.title(labels[train[-1][1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9f68tX2C0kr"
      },
      "source": [
        "# **Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6d5Wf8pTIU_"
      },
      "source": [
        "feature_train, label_train = compose_dataset(train_df)\n",
        "feature_test, label_test = compose_dataset(test_df)\n",
        "feature_val, label_val = compose_dataset(val_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJN60R8YTq1h"
      },
      "source": [
        "print('Train data shape: {}, Labels shape: {}'.format(feature_train.shape, label_train.shape))\n",
        "print('Test data shape: {}, Labels shape: {}'.format(feature_test.shape, label_test.shape))\n",
        "print('Validation data shape: {}, Labels shape: {}'.format(feature_val.shape, label_val.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XgFxa0YiHvO"
      },
      "source": [
        "print(label_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ymoh2AkRCWd"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "                                   zoom_range = 0.2, # Randomly zoom image \n",
        "                                   width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "                                   height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "                                   horizontal_flip = True)  # randomly flip images\n",
        "\n",
        "train_datagen.fit(feature_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukU0igCBDM5E"
      },
      "source": [
        "label_train = to_categorical(label_train)\n",
        "label_test = to_categorical(label_test)\n",
        "label_val = to_categorical(label_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XNcjm3jC87i"
      },
      "source": [
        "## **Visualisasi Image Data Generator yang di gunakan**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHvvvGJZ63KB"
      },
      "source": [
        "list_param=[\"rotation_range\",\"zoom_range\",\"width_shift_range\",\"height_shift_range\",\"horizontal_flip\",\"All\"]\n",
        "\n",
        "for i in list_param:\n",
        "    imagedatagenerator(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0hyPX13DO6A"
      },
      "source": [
        "# **Model CNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fywF8I4TW98q"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=8, kernel_size=(7,7), padding='same', activation='relu', input_shape=(200, 200, 1)))\n",
        "model.add(Conv2D(filters=8, kernel_size=(7,7), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "\n",
        "model.add(Conv2D(filters=16, kernel_size=(5,5), padding='same', activation='relu'))\n",
        "model.add(Conv2D(filters=16, kernel_size=(5,5), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "optimizer = Adam(lr=0.0001, decay=1e-5)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0NzHhMHjZdo"
      },
      "source": [
        "i=1\n",
        "for layer in model.layers:\n",
        "    if 'conv' in layer.name: \n",
        "        filters, bias= layer.get_weights()\n",
        "        print('Filters Shape: '+ str(filters.shape, )+\" \" + 'Bias Shape: '+str(bias.shape)+ \"<---- layer: \"+str(i))\n",
        "        print(\"-----------\")\n",
        "        i=i+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtJJcsCHDUcQ"
      },
      "source": [
        "## **visualisasi Layer Filter CNN ke 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d7_ciDjjbV_"
      },
      "source": [
        "layer= model.layers\n",
        "layer_1= layer[0]\n",
        "filter_1, bias_1= layer_1.get_weights()\n",
        "print(filter_1.shape, bias_1.shape)\n",
        "\n",
        "#Normalize the weights\n",
        "f_min, f_max = filter_1.min(), filter_1.max()\n",
        "filter_1 = (filter_1 - f_min) / (f_max - f_min)\n",
        "filter_1 = filter_1[:,:,0]\n",
        "\n",
        "fig= plt.figure(figsize=(20,20))\n",
        "for i in range(8):\n",
        "    ax = fig.add_subplot(1,8,i+1)\n",
        "    ax.imshow(filter_1[:,:,i], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kApkpLI3NrRi"
      },
      "source": [
        "## **visualisasi Layer Filter CNN ke 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAXBxhojNrRj"
      },
      "source": [
        "layer_2= layer[1]\n",
        "filter_2, bias_2= layer_2.get_weights()\n",
        "print(filter_2.shape, bias_2.shape)\n",
        "\n",
        "#Normalize the weights\n",
        "f_min2, f_max2 = filter_2.min(), filter_2.max()\n",
        "filter_2 = (filter_2 - f_min2) / (f_max2 - f_min2)\n",
        "filter_2 = filter_2[:,:,0]\n",
        "\n",
        "fig= plt.figure(figsize=(20,20))\n",
        "for i in range(8):\n",
        "    ax = fig.add_subplot(1,8,i+1)\n",
        "    ax.imshow(filter_2[:,:,i], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dOVzLTwDjkm"
      },
      "source": [
        "## **Hasil Implementasi filter CNN ke 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuUlbDddjxXQ"
      },
      "source": [
        "inp= model.inputs \n",
        "out1= model.layers[0].output  \n",
        "feature_map_1= Model(inputs= inp, outputs= out1)  \n",
        "\n",
        "img=cv2.imread('/content/chest_xray_backup/train/NORMAL/IM-0115-0001.jpeg', cv2.IMREAD_GRAYSCALE)   # Reading an Image\n",
        "img=cv2.resize(img,(200,200))               # Resizing an Image\n",
        "img = np.array(img)/255.0\n",
        "img = np.reshape(img, (200,200,1))\n",
        "input_img= np.expand_dims(img, axis=0)      # Expanding the dimension\n",
        "print(input_img.shape)                      # Printing out the size of the Input Image\n",
        "#-------------------------------------#---------------------------\n",
        "f1=feature_map_1.predict(input_img)        # predicting out the Image \n",
        "print(f1.shape)                            # Let's see the shape\n",
        "fig= plt.figure(figsize=(20,20))\n",
        "for i in range(8):\n",
        "    ax=fig.add_subplot(1,8,i+1)\n",
        "    ax.imshow(f1[0,:,:,i],cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10DKQUwlNUWr"
      },
      "source": [
        "## **Hasil Implementasi filter CNN ke 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B85Sn0coIqzl"
      },
      "source": [
        "inp= model.inputs \n",
        "out2= model.layers[1].output  \n",
        "feature_map_2= Model(inputs= inp, outputs= out2)  \n",
        "\n",
        "f2=feature_map_2.predict(input_img)        # predicting out the Image \n",
        "print(f2.shape)                            # Let's see the shape\n",
        "fig= plt.figure(figsize=(20,20))\n",
        "for i in range(8):\n",
        "    ax=fig.add_subplot(1,8,i+1)\n",
        "    ax.imshow(f2[0,:,:,i],cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc6KFWuuD2Yu"
      },
      "source": [
        "# **Melatih Model pada Validation Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1srIocp3XUd9"
      },
      "source": [
        "filepath=\"weights_best.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")) # Tempat dimana log tensorboard akan di\n",
        "callbacks_list.append(TensorBoard(logdir, histogram_freq=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8PIJUafXdaD"
      },
      "source": [
        "history = model.fit(train_datagen.flow(feature_train,label_train, batch_size=4), validation_data=(feature_val, label_val), epochs = 25, verbose = 1, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3BLL1WOEONr"
      },
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCZuwwkTEAqT"
      },
      "source": [
        "# **Evaluasi Model Pada data test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiZAuM1-bMx8"
      },
      "source": [
        "print(\"Loss of the model is - \" , model.evaluate(feature_test,label_test)[0])\n",
        "print(\"Accuracy of the model is - \" , model.evaluate(feature_test,label_test)[1]*100 , \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4v1tCk7dhml"
      },
      "source": [
        "predictions = np.argmax(model.predict(feature_test), axis=-1)\n",
        "predictions = predictions.reshape(1,-1)[0]\n",
        "predictions[:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOVoGIvLojCT"
      },
      "source": [
        "label_test_hat = model.predict(feature_test, batch_size=4)\n",
        "label_test_hat = np.argmax(label_test_hat, axis=1)\n",
        "label_test = np.argmax(label_test, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "968qCKY3ojv-"
      },
      "source": [
        "# calculate confusion matrix & classification report\n",
        "conf_m = confusion_matrix(label_test, label_test_hat)\n",
        "clas_r = classification_report(label_test, label_test_hat,target_names = ['Normal (Class 0)','Pneumonia (Class 1)'])\n",
        "\n",
        "# plot confusion matrix as heatmap\n",
        "plt.figure(figsize=(5,3))\n",
        "sns.set(font_scale=1.2)\n",
        "ax = sns.heatmap(conf_m, annot=True,xticklabels=['H', 'P'], yticklabels=['H', 'P'], cbar=False, cmap='Blues',linewidths=1, linecolor='black', fmt='.0f')\n",
        "plt.yticks(rotation=0)\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "ax.xaxis.set_ticks_position('top') \n",
        "plt.title('Confusion matrix - test data\\n(H - healthy/normal, P - pneumonia)')\n",
        "plt.show()\n",
        "\n",
        "# print classification report\n",
        "print('Classification report on test data')\n",
        "print(clas_r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgccJGobEfA1"
      },
      "source": [
        "# **Visualisasi Data Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIpiZ-7LlNmF"
      },
      "source": [
        "label_val_hat = model.predict(feature_val, batch_size=4)\n",
        "label_val_hat = np.argmax(label_val_hat, axis=1)\n",
        "label_val = np.argmax(label_val, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwm7Yn2flOIh"
      },
      "source": [
        "plt.figure(figsize=(20,15))\n",
        "for i,x in enumerate(feature_val):\n",
        "    plt.subplot(4,4,i+1)\n",
        "    plt.imshow(x.reshape(200, 200), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('Predicted: {}, Real: {}'.format(label_val_hat[i], label_val[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5snMXbdEtT1"
      },
      "source": [
        "# **RUC-AUC Curve**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bBQ1dlNFDbZ"
      },
      "source": [
        "## **Data Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUzOpLD4ZyR8"
      },
      "source": [
        "label_pred = model.predict(feature_test,batch_size= 4)\n",
        "label_pred = np.argmax(label_pred, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nGBD-lCaofv"
      },
      "source": [
        "fpr, tpr, threshold = roc_curve(label_test, label_pred)\n",
        "auc_test = auc(fpr, tpr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2zFU-G-cHaq"
      },
      "source": [
        "plt.plot(fpr, tpr, marker='.', label='cnn (area = {:.3f})'.format(auc_test))\n",
        "# axis labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hsqGdgPFGJs"
      },
      "source": [
        "## **Data Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxiNgcScgfI9"
      },
      "source": [
        "train_pred = model.predict(feature_train,batch_size= 4)\n",
        "train_pred = np.argmax(train_pred, axis=1)\n",
        "train_label_roc = np.argmax(label_train, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOu-J4mtgfJA"
      },
      "source": [
        "fpr_train, tpr_train, threshold = roc_curve(train_label_roc, train_pred)\n",
        "auc_train = auc(fpr_train, tpr_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZH-QvQBgfJC"
      },
      "source": [
        "plt.plot(fpr_train, tpr_train, marker='.', label='cnn (area = {:.3f})'.format(auc_train))\n",
        "# axis labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}